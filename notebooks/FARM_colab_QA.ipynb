{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FARM_colab-QA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBl4bRggZt7z",
        "outputId": "49673fb8-75bc-4ba2-c006-beae1827303c"
      },
      "source": [
        "# For Colab: Install FARM\n",
        "!pip install torch==1.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install farm==0.5.0"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.6.0+cu101 in /usr/local/lib/python3.7/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: farm==0.5.0 in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (3.0.10)\n",
            "Requirement already satisfied: mlflow==1.0.0 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.0.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.17.41)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (2.23.0)\n",
            "Requirement already satisfied: torch<1.7,>1.5 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.6.0+cu101)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.36.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.1.2)\n",
            "Requirement already satisfied: transformers==3.3.1 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (3.3.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (54.2.0)\n",
            "Requirement already satisfied: seqeval==0.0.12 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.0.12)\n",
            "Requirement already satisfied: dotmap==1.3.0 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: flask-restplus in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.13.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (5.4.8)\n",
            "Requirement already satisfied: Werkzeug==0.16.1 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.16.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (4.41.1)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors->farm==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: databricks-cli>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (0.14.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (3.13)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.2.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (2.8.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (7.1.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (0.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (3.1.14)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (3.17.2)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.5.8)\n",
            "Requirement already satisfied: docker>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (4.4.4)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (0.4.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (3.12.4)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.19.5)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (20.1.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->farm==0.5.0) (0.3.6)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.41 in /usr/local/lib/python3.7/dist-packages (from boto3->farm==0.5.0) (1.20.41)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->farm==0.5.0) (0.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch<1.7,>1.5->farm==0.5.0) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->farm==0.5.0) (0.22.2.post1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->farm==0.5.0) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->farm==0.5.0) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (20.9)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (0.8.1rc2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (0.1.95)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (3.0.12)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.12->farm==0.5.0) (2.4.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from flask-restplus->farm==0.5.0) (2.6.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from flask-restplus->farm==0.5.0) (2018.9)\n",
            "Requirement already satisfied: aniso8601>=0.82 in /usr/local/lib/python3.7/dist-packages (from flask-restplus->farm==0.5.0) (9.0.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.0->mlflow==1.0.0->farm==0.5.0) (0.8.9)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow==1.0.0->farm==0.5.0) (4.0.7)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow==1.0.0->farm==0.5.0) (1.1.4)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow==1.0.0->farm==0.5.0) (1.0.4)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker>=3.6.0->mlflow==1.0.0->farm==0.5.0) (0.58.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow==1.0.0->farm==0.5.0) (3.8.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow==1.0.0->farm==0.5.0) (1.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->farm==0.5.0) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->farm==0.5.0) (1.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3.1->farm==0.5.0) (2.4.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.12->farm==0.5.0) (2.10.0)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow==1.0.0->farm==0.5.0) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy->mlflow==1.0.0->farm==0.5.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy->mlflow==1.0.0->farm==0.5.0) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ7Apn7lc0HD"
      },
      "source": [
        "# QA Fine-tuning\n",
        "\n",
        "- Pretrained Model: [KoELECTRA](https://github.com/monologg/KoELECTRA)\n",
        "- Dataset: [AIhub QA dataset](https://aihub.or.kr/aidata/86)\n",
        "<center><img src=\"https://drive.google.com/uc?id=1RI9MoUB8QEfOzrvlVfOYaRvUeuNEW1cU\" alt=\"Fine-tuning\" width=\"100%\" height=\"30%\"></center>\n",
        "- MLFlow: [link](https://public-mlflow.deepset.ai/#/experiments/314/runs/2791c81d303f4e8daeb8fd08ba4e4fca)\n",
        "- Training environment: TITAN RTX x 4, batch_size = 96, early_stopped after 5200 batches.\n",
        "<center><img src=\"https://drive.google.com/uc?id=1MALTUUDly-G0izbHCsdC_kXnoRv78rxg\" alt=\"Fine-tuning\" width=\"60%\" height=\"30%\"></center>\n",
        "- Training results\n",
        "<center><img src=\"https://drive.google.com/uc?id=1ogM3bEHifxm0qiJ_kw18_GOQKOVzCZG7\" alt=\"Fine-tuning\" width=\"100%\" height=\"30%\"></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kGdDYXmaDWC",
        "outputId": "bcb60131-cb14-425f-ba7d-6cfebe804a27"
      },
      "source": [
        "# if you not trained the model please use it\n",
        "from pathlib import Path\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1crJKVxSi7z9abx6xL-Vvxw-RUJShTJ3z\"\n",
        "ckpt_path = Path(\".\") / \"ckpt\"\n",
        "if not ckpt_path.exists():\n",
        "    ckpt_path.mkdir()\n",
        "gdown.download(url, str(ckpt_path / \"best_aihub.tar\"), quiet=False)\n",
        "!tar -xvf ./ckpt/best_aihub.tar -C ./ckpt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1crJKVxSi7z9abx6xL-Vvxw-RUJShTJ3z\n",
            "To: /content/ckpt/best_aihub.tar\n",
            "450MB [00:02, 210MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "./best_aihub/\n",
            "./best_aihub/processor_config.json\n",
            "./best_aihub/language_model.bin\n",
            "./best_aihub/prediction_head_0.bin\n",
            "./best_aihub/vocab.txt\n",
            "./best_aihub/language_model_config.json\n",
            "./best_aihub/tokenizer_config.json\n",
            "./best_aihub/special_tokens_map.json\n",
            "./best_aihub/prediction_head_0_config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYuV9hFEd8va"
      },
      "source": [
        "from farm.infer import Inferencer, QAInferencer\n",
        "from pprint import PrettyPrinter\n",
        "\n",
        "context1 = \"제788회 로또 당첨번호‘2·10·11·19·35·39’ 보너스 번호 ‘29’ ... 1등 13명 각 14억원지난 6일 제788회 나눔로또 로또복권 추첨 결과 1등 당첨번호는 2·10·11·19·35·39의 6개다. 2등 보너스번호는 ‘29’이다. 로또 788회 로또당첨번호 6개를 모두 맞힌 1등 당첨자는 총 13명으로 각각 14억147만5154원씩 받게된다. 당첨번호 5개와 보너스 번호가 일치한 2등은 70명으로 4337만8993원, 당첨번호 5개를 맞힌 3등은 2257명으로 134만5384원 씩 받는다. 로또당첨번호 4개를 맞힌 4등(고정 당첨금 5만원)은 11만2504명, 로또 당첨번호 788회 3개가 일치한 5등(고정 당첨금 5000원)은 182만8701명이다. [사진=나눔로또 캡처]\"\n",
        "questions1 = [\n",
        "    \"3등은 당첨번호는 몇 개가 맞아야해?\",\n",
        "    \"제788회 로또 당첨번호의 보너스 번호는 뭐야?\"\n",
        "]\n",
        "answers1 = [\n",
        "    {'text': '당첨번호 5개', 'answer_start': 203},\n",
        "    {'text': ' ‘29’', 'answer_start': 38}\n",
        "]\n",
        "\n",
        "context2 = \"동원FB의 펫푸드 전문 브랜드 뉴트리플랜이 국내 최초 참치알을 넣어 만든 애묘 습식 파우치 뉴트리플랜 모이스트루 4종(사진)을 출시했다고 21일 밝혔다. 동원FB는 최근 약 30억 원을 투자해 국내 창원공장에 펫푸드 생산을 위한 라인을 증설했다. 증설된 라인에서는 참치와 펫푸드 노하우를 활용한 다양한 애묘, 애견용 펫푸드를 선보일 예정이다. 그 첫 번째 시리즈가 국내 최초로 참치알을 활용해 만든 애묘용 습식파우치 모이스트루 4종(참치, 참치와 멸치, 참치와 닭고기, 참치와 연어)이다. 뉴트리플랜 모이스트루 4종은 육식동물 고양이의 건강한 습식 습관을 위한 고급 파우치 제품이다. 필수 아미노산인 타우린과 아르기닌을 다량 함유하고 있는 참치 붉은 살과 단백질, 오메가-3 지방산 및 미네랄이 풍부하며 기호성이 높은 참치알을 담았다. 또한 고양이의 하부요로기 질환에 도움을 주는 크랜베리와 장관환경과 배변상태 개선을 지원하는 프리바이오틱 성분인 이눌린을 첨가했다. 특히 28년 간 펫푸드를 만들어 일본에 수출해 온 동원FB가 국내에서 직접 만든 제품으로 믿을 수 있다. win5858@fnnews.com 김성원 기자\"\n",
        "\n",
        "questions2 = [\n",
        "    \"참치알을 넣어 만든 펫푸드를 출시한 곳은 어디지?\",\n",
        "    \"동원FB가 새로 증설된 펫푸드 생산라인에서 선보인 첫 번째 시리즈는 뭐야?\"\n",
        "]\n",
        "answers2 = [\n",
        "    {'text': '동원FB', 'answer_start': 513},\n",
        "    {'text': '뉴트리플랜 모이스트루 4종은 육식동물 고양이의 건강한 습식 습관을 위한 고급 파우치 제품이다', 'answer_start': 274}\n",
        "]\n",
        "basic_texts = [\n",
        "    {\n",
        "        \"questions\": questions1,\n",
        "        \"text\": context1\n",
        "    },\n",
        "    {\n",
        "        \"questions\": questions2,\n",
        "        \"text\": context2\n",
        "    }\n",
        "]"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcgwJbYCDrF9",
        "outputId": "c1b5cc5b-12e1-44a9-e2fc-97f6d4e62ecd"
      },
      "source": [
        "infer_model = QAInferencer.load(    \n",
        "    model_name_or_path=\"./ckpt/best_aihub\",\n",
        "    extraction_strategy=\"per_token\",\n",
        "    batch_size=2,\n",
        "    max_seq_len=512, \n",
        "    doc_stride=128,\n",
        "    task_type=\"question_answering\",\n",
        ")\n",
        "result = infer_model.inference_from_dicts(dicts=basic_texts)\n",
        "print()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/31/2021 08:35:02 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
            "03/31/2021 08:35:07 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
            "03/31/2021 08:35:07 - WARNING - farm.modeling.prediction_head -   Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
            "03/31/2021 08:35:07 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "03/31/2021 08:35:07 - INFO - farm.modeling.prediction_head -   Loading prediction head from ckpt/best_aihub/prediction_head_0.bin\n",
            "03/31/2021 08:35:07 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'ElectraTokenizer'\n",
            "03/31/2021 08:35:08 - INFO - farm.data_handler.processor -   Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
            "03/31/2021 08:35:08 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
            "03/31/2021 08:35:08 - INFO - farm.infer -   Got ya 1 parallel workers to do inference ...\n",
            "03/31/2021 08:35:08 - INFO - farm.infer -    0 \n",
            "03/31/2021 08:35:08 - INFO - farm.infer -   /w\\\n",
            "03/31/2021 08:35:08 - INFO - farm.infer -   /'\\\n",
            "03/31/2021 08:35:08 - INFO - farm.infer -   \n",
            "03/31/2021 08:35:08 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "03/31/2021 08:35:08 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 0-1-0\n",
            "Clear Text: \n",
            " \tpassage_text: 제788회 로또 당첨번호‘2·10·11·19·35·39’ 보너스 번호 ‘29’ ... 1등 13명 각 14억원지난 6일 제788회 나눔로또 로또복권 추첨 결과 1등 당첨번호는 2·10·11·19·35·39의 6개다. 2등 보너스번호는 ‘29’이다. 로또 788회 로또당첨번호 6개를 모두 맞힌 1등 당첨자는 총 13명으로 각각 14억147만5154원씩 받게된다. 당첨번호 5개와 보너스 번호가 일치한 2등은 70명으로 4337만8993원, 당첨번호 5개를 맞힌 3등은 2257명으로 134만5384원 씩 받는다. 로또당첨번호 4개를 맞힌 4등(고정 당첨금 5만원)은 11만2504명, 로또 당첨번호 788회 3개가 일치한 5등(고정 당첨금 5000원)은 182만8701명이다. [사진=나눔로또 캡처]\n",
            " \tquestion_text: 제788회 로또 당첨번호의 보너스 번호는 뭐야?\n",
            " \tpassage_id: 0\n",
            " \tanswers: []\n",
            "Tokenized: \n",
            " \tpassage_start_t: 0\n",
            " \tpassage_tokens: ['제', '##78', '##8', '##회', '로또', '당첨', '##번', '##호', '‘', '2', '·', '10', '·', '11', '·', '19', '·', '35', '·', '39', '’', '보너스', '번호', '‘', '29', '’', '.', '.', '.', '1', '##등', '13', '##명', '각', '14', '##억', '##원지', '##난', '6', '##일', '제', '##78', '##8', '##회', '나눔', '##로', '##또', '로또', '##복', '##권', '추첨', '결과', '1', '##등', '당첨', '##번', '##호', '##는', '2', '·', '10', '·', '11', '·', '19', '·', '35', '·', '39', '##의', '6', '##개', '##다', '.', '2', '##등', '보너스', '##번', '##호', '##는', '‘', '29', '’', '이', '##다', '.', '로또', '78', '##8', '##회', '로또', '##당', '##첨', '##번', '##호', '6', '##개', '##를', '모두', '맞', '##힌', '1', '##등', '당첨자', '##는', '총', '13', '##명', '##으로', '각각', '14', '##억', '##14', '##7', '##만', '##51', '##54', '##원', '##씩', '받', '##게', '##된', '##다', '.', '당첨', '##번', '##호', '5', '##개', '##와', '보너스', '번호', '##가', '일치', '##한', '2', '##등', '##은', '70', '##명', '##으로', '43', '##37', '##만', '##89', '##93', '##원', ',', '당첨', '##번', '##호', '5', '##개', '##를', '맞', '##힌', '3', '##등', '##은', '225', '##7', '##명', '##으로', '134', '##만', '##53', '##84', '##원', '씩', '받', '##는', '##다', '.', '로또', '##당', '##첨', '##번', '##호', '4', '##개', '##를', '맞', '##힌', '4', '##등', '(', '고정', '당첨', '##금', '5', '##만', '##원', ')', '은', '11', '##만', '##25', '##0', '##4', '##명', ',', '로또', '당첨', '##번', '##호', '78', '##8', '##회', '3', '##개', '##가', '일치', '##한', '5', '##등', '(', '고정', '당첨', '##금', '5000', '##원', ')', '은', '182', '##만', '##87', '##0', '##1', '##명', '##이다', '.', '[', '사진', '=', '나눔', '##로', '##또', '캡처', ']']\n",
            " \tpassage_offsets: [0, 1, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 30, 32, 36, 39, 40, 42, 44, 45, 46, 48, 49, 51, 53, 55, 57, 59, 60, 62, 64, 65, 67, 68, 70, 71, 73, 75, 76, 78, 80, 81, 83, 86, 89, 90, 92, 94, 95, 96, 98, 99, 100, 102, 103, 105, 106, 108, 109, 111, 112, 114, 116, 117, 118, 119, 121, 122, 124, 127, 128, 129, 131, 132, 134, 135, 136, 137, 139, 142, 144, 145, 147, 149, 150, 151, 152, 154, 155, 156, 158, 161, 162, 164, 165, 167, 170, 172, 174, 176, 177, 180, 183, 185, 186, 188, 189, 190, 192, 194, 195, 197, 198, 199, 200, 201, 203, 205, 206, 208, 209, 210, 212, 216, 218, 220, 222, 224, 225, 226, 228, 230, 231, 234, 236, 238, 239, 241, 243, 244, 246, 248, 249, 251, 252, 253, 255, 256, 258, 259, 260, 262, 265, 266, 267, 270, 273, 274, 276, 278, 280, 282, 283, 284, 285, 287, 289, 290, 291, 292, 294, 295, 296, 298, 299, 301, 302, 303, 304, 307, 309, 311, 312, 313, 314, 315, 317, 319, 320, 322, 323, 324, 325, 327, 330, 332, 333, 335, 337, 338, 340, 341, 342, 344, 346, 348, 349, 350, 351, 354, 356, 358, 362, 363, 364, 366, 369, 370, 372, 373, 374, 375, 377, 379, 380, 382, 383, 385, 386, 388, 390]\n",
            " \tpassage_start_of_word: [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
            " \tquestion_tokens: ['제', '##78', '##8', '##회', '로또', '당첨', '##번', '##호', '##의', '보너스', '번호', '##는', '뭐', '##야', '?']\n",
            " \tquestion_offsets: [0, 1, 3, 4, 6, 9, 11, 12, 13, 15, 19, 21, 23, 24, 25]\n",
            " \tquestion_start_of_word: [1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            " \tanswers: []\n",
            " \tdocument_offsets: [0, 1, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 30, 32, 36, 39, 40, 42, 44, 45, 46, 48, 49, 51, 53, 55, 57, 59, 60, 62, 64, 65, 67, 68, 70, 71, 73, 75, 76, 78, 80, 81, 83, 86, 89, 90, 92, 94, 95, 96, 98, 99, 100, 102, 103, 105, 106, 108, 109, 111, 112, 114, 116, 117, 118, 119, 121, 122, 124, 127, 128, 129, 131, 132, 134, 135, 136, 137, 139, 142, 144, 145, 147, 149, 150, 151, 152, 154, 155, 156, 158, 161, 162, 164, 165, 167, 170, 172, 174, 176, 177, 180, 183, 185, 186, 188, 189, 190, 192, 194, 195, 197, 198, 199, 200, 201, 203, 205, 206, 208, 209, 210, 212, 216, 218, 220, 222, 224, 225, 226, 228, 230, 231, 234, 236, 238, 239, 241, 243, 244, 246, 248, 249, 251, 252, 253, 255, 256, 258, 259, 260, 262, 265, 266, 267, 270, 273, 274, 276, 278, 280, 282, 283, 284, 285, 287, 289, 290, 291, 292, 294, 295, 296, 298, 299, 301, 302, 303, 304, 307, 309, 311, 312, 313, 314, 315, 317, 319, 320, 322, 323, 324, 325, 327, 330, 332, 333, 335, 337, 338, 340, 341, 342, 344, 346, 348, 349, 350, 351, 354, 356, 358, 362, 363, 364, 366, 369, 370, 372, 373, 374, 375, 377, 379, 380, 382, 383, 385, 386, 388, 390]\n",
            "Features: \n",
            " \tinput_ids: [2, 3288, 26065, 4193, 4213, 20627, 11660, 4467, 4029, 4234, 13973, 7916, 4034, 2702, 4474, 35, 3, 3288, 26065, 4193, 4213, 20627, 11660, 4467, 4029, 144, 22, 107, 6242, 107, 6307, 107, 6238, 107, 7203, 107, 8079, 145, 13973, 7916, 144, 6861, 145, 18, 18, 18, 21, 4291, 6431, 4282, 2011, 6461, 4639, 17510, 4360, 26, 4366, 3288, 26065, 4193, 4213, 10309, 4239, 4509, 20627, 4706, 4046, 13279, 6331, 21, 4291, 11660, 4467, 4029, 4034, 22, 107, 6242, 107, 6307, 107, 6238, 107, 7203, 107, 8079, 4234, 26, 4217, 4176, 18, 22, 4291, 13973, 4467, 4029, 4034, 144, 6861, 145, 3240, 4176, 18, 20627, 9801, 4193, 4213, 20627, 4403, 4914, 4467, 4029, 26, 4217, 4110, 6312, 2639, 4514, 21, 4291, 18886, 4034, 3467, 6431, 4282, 10749, 6887, 6461, 4639, 22484, 4056, 4172, 29714, 28831, 4005, 5949, 2734, 4325, 4880, 4176, 18, 11660, 4467, 4029, 25, 4217, 4192, 13973, 7916, 4070, 9524, 4283, 22, 4291, 4112, 7092, 4282, 10749, 8134, 27046, 4172, 27322, 29157, 4005, 16, 11660, 4467, 4029, 25, 4217, 4110, 2639, 4514, 23, 4291, 4112, 21051, 4056, 4282, 10749, 19154, 4172, 29100, 29412, 4005, 3072, 2734, 4034, 4176, 18, 20627, 4403, 4914, 4467, 4029, 24, 4217, 4110, 2639, 4514, 24, 4291, 12, 8546, 11660, 4309, 25, 4172, 4005, 13, 3231, 6307, 4172, 22317, 4058, 4204, 4282, 16, 20627, 11660, 4467, 4029, 9801, 4193, 4213, 23, 4217, 4070, 9524, 4283, 25, 4291, 12, 8546, 11660, 4309, 7822, 4005, 13, 3231, 16783, 4172, 29137, 4058, 4057, 4282, 24387, 18, 63, 6471, 33, 10309, 4239, 4509, 25755, 65, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tanswer_type_ids: [0]\n",
            " \tpassage_start_t: 0\n",
            " \tstart_of_word: [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tlabels: [[0 0]]\n",
            " \tid: [0, 1, 0]\n",
            " \tseq_2_start_t: 17\n",
            " \tspan_mask: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "_____________________________________________________\n",
            "03/31/2021 08:35:08 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 1-0-0\n",
            "Clear Text: \n",
            " \tpassage_text: 동원FB의 펫푸드 전문 브랜드 뉴트리플랜이 국내 최초 참치알을 넣어 만든 애묘 습식 파우치 뉴트리플랜 모이스트루 4종(사진)을 출시했다고 21일 밝혔다. 동원FB는 최근 약 30억 원을 투자해 국내 창원공장에 펫푸드 생산을 위한 라인을 증설했다. 증설된 라인에서는 참치와 펫푸드 노하우를 활용한 다양한 애묘, 애견용 펫푸드를 선보일 예정이다. 그 첫 번째 시리즈가 국내 최초로 참치알을 활용해 만든 애묘용 습식파우치 모이스트루 4종(참치, 참치와 멸치, 참치와 닭고기, 참치와 연어)이다. 뉴트리플랜 모이스트루 4종은 육식동물 고양이의 건강한 습식 습관을 위한 고급 파우치 제품이다. 필수 아미노산인 타우린과 아르기닌을 다량 함유하고 있는 참치 붉은 살과 단백질, 오메가-3 지방산 및 미네랄이 풍부하며 기호성이 높은 참치알을 담았다. 또한 고양이의 하부요로기 질환에 도움을 주는 크랜베리와 장관환경과 배변상태 개선을 지원하는 프리바이오틱 성분인 이눌린을 첨가했다. 특히 28년 간 펫푸드를 만들어 일본에 수출해 온 동원FB가 국내에서 직접 만든 제품으로 믿을 수 있다. win5858@fnnews.com 김성원 기자\n",
            " \tquestion_text: 참치알을 넣어 만든 펫푸드를 출시한 곳은 어디지?\n",
            " \tpassage_id: 0\n",
            " \tanswers: []\n",
            "Tokenized: \n",
            " \tpassage_start_t: 0\n",
            " \tpassage_tokens: ['동원', '##F', '##B', '##의', '펫', '##푸드', '전문', '브랜드', '뉴트', '##리', '##플랜', '##이', '국내', '최초', '참치', '##알', '##을', '넣', '##어', '만든', '애', '##묘', '습', '##식', '파우', '##치', '뉴트', '##리', '##플랜', '모이', '##스트', '##루', '4', '##종', '(', '사진', ')', '을', '출시', '##했', '##다고', '21', '##일', '밝혔', '##다', '.', '동원', '##F', '##B', '##는', '최근', '약', '30', '##억', '원', '##을', '투자', '##해', '국내', '창원', '##공', '##장', '##에', '펫', '##푸드', '생산', '##을', '위한', '라인', '##을', '증설', '##했', '##다', '.', '증설', '##된', '라인', '##에', '##서는', '참치', '##와', '펫', '##푸드', '노하우', '##를', '활용', '##한', '다양', '##한', '애', '##묘', ',', '애견', '##용', '펫', '##푸드', '##를', '선보일', '예정', '##이다', '.', '그', '첫', '번', '##째', '시리즈', '##가', '국내', '최초', '##로', '참치', '##알', '##을', '활용', '##해', '만든', '애', '##묘', '##용', '습', '##식', '##파', '##우치', '모이', '##스트', '##루', '4', '##종', '(', '참치', ',', '참치', '##와', '멸치', ',', '참치', '##와', '닭고기', ',', '참치', '##와', '연어', ')', '이', '##다', '.', '뉴트', '##리', '##플랜', '모이', '##스트', '##루', '4', '##종', '##은', '육식', '##동물', '고양이', '##의', '건강', '##한', '습', '##식', '습관', '##을', '위한', '고급', '파우', '##치', '제품', '##이다', '.', '필수', '아미노산', '##인', '타우', '##린', '##과', '아르', '##기', '##닌', '##을', '다량', '함유', '##하', '##고', '있', '##는', '참치', '붉', '##은', '살', '##과', '단백질', ',', '오메가', '-', '3', '지방산', '및', '미네랄', '##이', '풍부', '##하', '##며', '기호', '##성이', '높', '##은', '참치', '##알', '##을', '담', '##았', '##다', '.', '또한', '고양이', '##의', '하부', '##요', '##로', '##기', '질환', '##에', '도움', '##을', '주', '##는', '크', '##랜', '##베리', '##와', '장관', '##환경', '##과', '배변', '##상', '##태', '개선', '##을', '지원', '##하', '##는', '프리', '##바이', '##오', '##틱', '성분', '##인', '이', '##눌', '##린', '##을', '첨가', '##했', '##다', '.', '특히', '28', '##년', '간', '펫', '##푸드', '##를', '만들', '##어', '일본', '##에', '수출', '##해', '온', '동원', '##F', '##B', '##가', '국내', '##에', '##서', '직접', '만든', '제품', '##으로', '믿', '##을', '수', '있', '##다', '.', 'w', '##in', '##58', '##58', '@', 'f', '##nn', '##ew', '##s', '.', 'com', '김성', '##원', '기자']\n",
            " \tpassage_offsets: [0, 2, 3, 4, 6, 7, 10, 13, 17, 19, 20, 22, 24, 27, 30, 32, 33, 35, 36, 38, 41, 42, 44, 45, 47, 49, 51, 53, 54, 57, 59, 61, 63, 64, 65, 66, 68, 69, 71, 73, 74, 77, 79, 81, 83, 84, 86, 88, 89, 90, 92, 95, 97, 99, 101, 102, 104, 106, 108, 111, 113, 114, 115, 117, 118, 121, 123, 125, 128, 130, 132, 134, 135, 136, 138, 140, 142, 144, 145, 148, 150, 152, 153, 156, 159, 161, 163, 165, 167, 169, 170, 171, 173, 175, 177, 178, 180, 182, 186, 188, 190, 192, 194, 196, 197, 199, 202, 204, 207, 209, 211, 213, 214, 216, 218, 220, 223, 224, 225, 227, 228, 229, 230, 233, 235, 237, 239, 240, 241, 242, 244, 246, 248, 250, 252, 254, 256, 258, 261, 263, 265, 267, 269, 270, 271, 272, 274, 276, 277, 280, 282, 284, 286, 287, 288, 290, 292, 295, 298, 300, 302, 304, 305, 307, 309, 311, 314, 317, 319, 321, 323, 325, 327, 330, 334, 336, 338, 339, 341, 343, 344, 345, 347, 350, 352, 353, 355, 356, 358, 361, 362, 364, 365, 367, 370, 372, 375, 376, 378, 382, 384, 387, 389, 391, 392, 394, 396, 399, 400, 402, 404, 405, 407, 408, 409, 410, 412, 415, 418, 420, 422, 423, 424, 426, 428, 430, 432, 434, 435, 437, 438, 439, 441, 443, 445, 447, 449, 451, 452, 454, 456, 458, 460, 461, 463, 465, 467, 468, 470, 472, 474, 475, 476, 477, 479, 481, 482, 483, 485, 488, 490, 492, 494, 495, 497, 499, 501, 503, 505, 507, 509, 511, 513, 515, 516, 517, 519, 521, 522, 524, 527, 530, 532, 535, 536, 538, 540, 541, 542, 544, 545, 547, 549, 551, 552, 553, 555, 557, 558, 559, 563, 565, 567]\n",
            " \tpassage_start_of_word: [1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
            " \tquestion_tokens: ['참치', '##알', '##을', '넣', '##어', '만든', '펫', '##푸드', '##를', '출시', '##한', '곳', '##은', '어디', '##지', '?']\n",
            " \tquestion_offsets: [0, 2, 3, 5, 6, 8, 11, 12, 14, 16, 18, 20, 21, 23, 25, 26]\n",
            " \tquestion_start_of_word: [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            " \tanswers: []\n",
            " \tdocument_offsets: [0, 2, 3, 4, 6, 7, 10, 13, 17, 19, 20, 22, 24, 27, 30, 32, 33, 35, 36, 38, 41, 42, 44, 45, 47, 49, 51, 53, 54, 57, 59, 61, 63, 64, 65, 66, 68, 69, 71, 73, 74, 77, 79, 81, 83, 84, 86, 88, 89, 90, 92, 95, 97, 99, 101, 102, 104, 106, 108, 111, 113, 114, 115, 117, 118, 121, 123, 125, 128, 130, 132, 134, 135, 136, 138, 140, 142, 144, 145, 148, 150, 152, 153, 156, 159, 161, 163, 165, 167, 169, 170, 171, 173, 175, 177, 178, 180, 182, 186, 188, 190, 192, 194, 196, 197, 199, 202, 204, 207, 209, 211, 213, 214, 216, 218, 220, 223, 224, 225, 227, 228, 229, 230, 233, 235, 237, 239, 240, 241, 242, 244, 246, 248, 250, 252, 254, 256, 258, 261, 263, 265, 267, 269, 270, 271, 272, 274, 276, 277, 280, 282, 284, 286, 287, 288, 290, 292, 295, 298, 300, 302, 304, 305, 307, 309, 311, 314, 317, 319, 321, 323, 325, 327, 330, 334, 336, 338, 339, 341, 343, 344, 345, 347, 350, 352, 353, 355, 356, 358, 361, 362, 364, 365, 367, 370, 372, 375, 376, 378, 382, 384, 387, 389, 391, 392, 394, 396, 399, 400, 402, 404, 405, 407, 408, 409, 410, 412, 415, 418, 420, 422, 423, 424, 426, 428, 430, 432, 434, 435, 437, 438, 439, 441, 443, 445, 447, 449, 451, 452, 454, 456, 458, 460, 461, 463, 465, 467, 468, 470, 472, 474, 475, 476, 477, 479, 481, 482, 483, 485, 488, 490, 492, 494, 495, 497, 499, 501, 503, 505, 507, 509, 511, 513, 515, 516, 517, 519, 521, 522, 524, 527, 530, 532, 535, 536, 538, 540, 541, 542, 544, 545, 547, 549, 551, 552, 553, 555, 557, 558, 559, 563, 565, 567]\n",
            "Features: \n",
            " \tinput_ids: [2, 17082, 4435, 4292, 2278, 4025, 6852, 3712, 22817, 4110, 6980, 4283, 2084, 4112, 6769, 4200, 35, 3, 8306, 4399, 4015, 4234, 3712, 22817, 6367, 6955, 33975, 4108, 33547, 4007, 6359, 7528, 17082, 4435, 4292, 2278, 4025, 6852, 3093, 4406, 3005, 4083, 14623, 4332, 33975, 4108, 33547, 11935, 6334, 4182, 24, 4317, 12, 6471, 13, 3232, 6980, 4398, 7218, 6591, 4366, 6308, 4176, 18, 8306, 4399, 4015, 4034, 6347, 3103, 6332, 4639, 3201, 4292, 6337, 4151, 6359, 8768, 4333, 4048, 4073, 3712, 22817, 6552, 4292, 6311, 7575, 4292, 16230, 4398, 4176, 18, 16230, 4880, 7575, 4073, 28893, 17082, 4192, 3712, 22817, 11629, 4110, 6649, 4283, 6417, 4283, 3093, 4406, 16, 23918, 4297, 3712, 22817, 4110, 14438, 6446, 24387, 18, 2126, 3449, 2755, 4704, 7487, 4070, 6359, 7528, 4239, 17082, 4435, 4292, 6649, 4151, 6852, 3093, 4406, 4297, 3005, 4083, 4125, 19881, 11935, 6334, 4182, 24, 4317, 12, 17082, 16, 17082, 4192, 18990, 16, 17082, 4192, 20404, 16, 17082, 4192, 14875, 13, 3240, 4176, 18, 33975, 4108, 33547, 11935, 6334, 4182, 24, 4317, 4112, 26303, 31781, 9475, 4234, 6652, 4283, 3005, 4083, 9147, 4292, 6311, 8084, 14623, 4332, 6466, 24387, 18, 8329, 26649, 4139, 26205, 4026, 4047, 8123, 4031, 4577, 4292, 24286, 11391, 4279, 4219, 3249, 4034, 17082, 2804, 4112, 2888, 4047, 12143, 16, 21485, 17, 23, 27138, 2728, 20166, 4007, 9005, 4279, 4815, 11740, 15650, 2304, 4112, 17082, 4435, 4292, 2357, 4494, 4176, 18, 6380, 9475, 4234, 20595, 4150, 4239, 4031, 8389, 4073, 6750, 4292, 3323, 4034, 3581, 4663, 13628, 4192, 6610, 8543, 4047, 31093, 4081, 4367, 6707, 4292, 6310, 4279, 4034, 7210, 10184, 4127, 4685, 8685, 4139, 3240, 5063, 4026, 4292, 13937, 4398, 4176, 18, 6342, 6771, 4556, 2012, 3712, 22817, 4110, 6284, 4025, 6320, 4073, 6910, 4151, 3160, 8306, 4399, 4015, 4070, 6359, 4073, 4129, 6493, 6852, 6466, 10749, 2721, 4292, 2967, 3249, 4176, 18, 91, 6420, 30033, 30033, 36, 74, 10165, 9285, 4021, 18, 7906, 9239, 4005, 6405, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tanswer_type_ids: [0]\n",
            " \tpassage_start_t: 0\n",
            " \tstart_of_word: [0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tlabels: [[0 0]]\n",
            " \tid: [1, 0, 0]\n",
            " \tseq_2_start_t: 18\n",
            " \tspan_mask: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "_____________________________________________________\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:07<00:00,  3.95s/ Batches]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc_IgU7AGDlV",
        "outputId": "f2f0244c-93cd-4dd6-bd6c-269fb220fc12"
      },
      "source": [
        "import termcolor\n",
        "\n",
        "def sprint(s, n=85):\n",
        "    for i in range(len(s) // n):\n",
        "        print(\"  \", s[i*n:(i*n+n)])\n",
        "    print(\"  \", s[(i*n+n):])\n",
        "\n",
        "true_answers = answers1 + answers2\n",
        "contexts = [context1, context1, context2, context2]\n",
        "for i, (batch) in enumerate(result):\n",
        "    predictions = batch[\"predictions\"][0]\n",
        "    answers = predictions[\"answers\"][0]\n",
        "    \n",
        "    context = contexts[i]\n",
        "    true_answer = true_answers[i]\n",
        "\n",
        "    question = predictions[\"question\"]\n",
        "    \n",
        "    offset_answer_start = answers[\"offset_answer_start\"]\n",
        "    offset_answer_end = answers[\"offset_answer_end\"]\n",
        "    predict_answer = context[offset_answer_start:offset_answer_end]\n",
        "    predict_answer_colored = termcolor.colored(predict_answer, \"red\", attrs=[\"bold\"])\n",
        "    predict_context_colored = context[:offset_answer_start] + predict_answer_colored + context[offset_answer_end:]\n",
        "    print(termcolor.colored(f\"[Question] {question}\", attrs=[\"bold\"]))\n",
        "    print(f\"[Predict: Context]\")\n",
        "    sprint(predict_context_colored)\n",
        "    print(f\"[Predict: Answer] {predict_answer} | {offset_answer_start}:{offset_answer_end}\")\n",
        "    \n",
        "    true_answer_text = true_answer['text']\n",
        "    true_answer_start = true_answer['answer_start']\n",
        "    true_answer_end = true_answer_start+len(true_answer_text)\n",
        "    true_answer_colored = termcolor.colored(true_answer_text, \"blue\", attrs=[\"bold\"])\n",
        "    true_context_colored = context[:true_answer_start] + true_answer_colored + context[true_answer_end:]\n",
        "    print(f\"[True: Context]\")\n",
        "    sprint(true_context_colored)\n",
        "    print(f\"[True: Answer] {true_answer_text} | {true_answer_start}:{true_answer_end}\")\n",
        "    print()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m[Question] 3등은 당첨번호는 몇 개가 맞아야해?\u001b[0m\n",
            "[Predict: Context]\n",
            "   제788회 로또 당첨번호‘2·10·11·19·35·39’ 보너스 번호 ‘29’ ... 1등 13명 각 14억원지난 6일 제788회 나눔로또 로또복권 추첨\n",
            "    결과 1등 당첨번호는 2·10·11·19·35·39의 6개다. 2등 보너스번호는 ‘29’이다. 로또 788회 로또당첨번호 6개를 모두 맞힌 1등 당첨자\n",
            "   는 총 13명으로 각각 14억147만5154원씩 받게된다. 당첨번호 5개와 보너스 번호가 일치한 2등은 70명으로 4337만8993원, 당첨번호 \u001b[1m\n",
            "   \u001b[31m5개\u001b[0m를 맞힌 3등은 2257명으로 134만5384원 씩 받는다. 로또당첨번호 4개를 맞힌 4등(고정 당첨금 5만원)은 11만2504명, \n",
            "   로또 당첨번호 788회 3개가 일치한 5등(고정 당첨금 5000원)은 182만8701명이다. [사진=나눔로또 캡처]\n",
            "[Predict: Answer] 5개 | 251:253\n",
            "[True: Context]\n",
            "   제788회 로또 당첨번호‘2·10·11·19·35·39’ 보너스 번호 ‘29’ ... 1등 13명 각 14억원지난 6일 제788회 나눔로또 로또복권 추첨\n",
            "    결과 1등 당첨번호는 2·10·11·19·35·39의 6개다. 2등 보너스번호는 ‘29’이다. 로또 788회 로또당첨번호 6개를 모두 맞힌 1등 당첨자\n",
            "   는 총 13명으로 각각 14억147만5154원씩 받게된다. \u001b[1m\u001b[34m당첨번호 5개\u001b[0m와 보너스 번호가 일치한 2등은 70명으로 4337만899\n",
            "   3원, 당첨번호 5개를 맞힌 3등은 2257명으로 134만5384원 씩 받는다. 로또당첨번호 4개를 맞힌 4등(고정 당첨금 5만원)은 11만2504명, \n",
            "   로또 당첨번호 788회 3개가 일치한 5등(고정 당첨금 5000원)은 182만8701명이다. [사진=나눔로또 캡처]\n",
            "[True: Answer] 당첨번호 5개 | 203:210\n",
            "\n",
            "\u001b[1m[Question] 제788회 로또 당첨번호의 보너스 번호는 뭐야?\u001b[0m\n",
            "[Predict: Context]\n",
            "   제788회 로또 당첨번호\u001b[1m\u001b[31m‘2·10·11·19·35·39’ 보너스 번호 ‘29’\u001b[0m ... 1등 13명 각 14억원지난 6일 제788회\n",
            "    나눔로또 로또복권 추첨 결과 1등 당첨번호는 2·10·11·19·35·39의 6개다. 2등 보너스번호는 ‘29’이다. 로또 788회 로또당첨번호 6개를\n",
            "    모두 맞힌 1등 당첨자는 총 13명으로 각각 14억147만5154원씩 받게된다. 당첨번호 5개와 보너스 번호가 일치한 2등은 70명으로 4337만899\n",
            "   3원, 당첨번호 5개를 맞힌 3등은 2257명으로 134만5384원 씩 받는다. 로또당첨번호 4개를 맞힌 4등(고정 당첨금 5만원)은 11만2504명, \n",
            "   로또 당첨번호 788회 3개가 일치한 5등(고정 당첨금 5000원)은 182만8701명이다. [사진=나눔로또 캡처]\n",
            "[Predict: Answer] ‘2·10·11·19·35·39’ 보너스 번호 ‘29’ | 13:43\n",
            "[True: Context]\n",
            "   제788회 로또 당첨번호‘2·10·11·19·35·39’ 보너스 번호\u001b[1m\u001b[34m ‘29’\u001b[0m ... 1등 13명 각 14억원지난 6일 제788회\n",
            "    나눔로또 로또복권 추첨 결과 1등 당첨번호는 2·10·11·19·35·39의 6개다. 2등 보너스번호는 ‘29’이다. 로또 788회 로또당첨번호 6개를\n",
            "    모두 맞힌 1등 당첨자는 총 13명으로 각각 14억147만5154원씩 받게된다. 당첨번호 5개와 보너스 번호가 일치한 2등은 70명으로 4337만899\n",
            "   3원, 당첨번호 5개를 맞힌 3등은 2257명으로 134만5384원 씩 받는다. 로또당첨번호 4개를 맞힌 4등(고정 당첨금 5만원)은 11만2504명, \n",
            "   로또 당첨번호 788회 3개가 일치한 5등(고정 당첨금 5000원)은 182만8701명이다. [사진=나눔로또 캡처]\n",
            "[True: Answer]  ‘29’ | 38:43\n",
            "\n",
            "\u001b[1m[Question] 참치알을 넣어 만든 펫푸드를 출시한 곳은 어디지?\u001b[0m\n",
            "[Predict: Context]\n",
            "   \u001b[1m\u001b[31m동원FB의 펫푸드 전문 브랜드 뉴트리플랜\u001b[0m이 국내 최초 참치알을 넣어 만든 애묘 습식 파우치 뉴트리플랜 모이스트루 4종(사진)을 출\n",
            "   시했다고 21일 밝혔다. 동원FB는 최근 약 30억 원을 투자해 국내 창원공장에 펫푸드 생산을 위한 라인을 증설했다. 증설된 라인에서는 참치와 펫푸드 노\n",
            "   하우를 활용한 다양한 애묘, 애견용 펫푸드를 선보일 예정이다. 그 첫 번째 시리즈가 국내 최초로 참치알을 활용해 만든 애묘용 습식파우치 모이스트루 4종(\n",
            "   참치, 참치와 멸치, 참치와 닭고기, 참치와 연어)이다. 뉴트리플랜 모이스트루 4종은 육식동물 고양이의 건강한 습식 습관을 위한 고급 파우치 제품이다. \n",
            "   필수 아미노산인 타우린과 아르기닌을 다량 함유하고 있는 참치 붉은 살과 단백질, 오메가-3 지방산 및 미네랄이 풍부하며 기호성이 높은 참치알을 담았다. \n",
            "   또한 고양이의 하부요로기 질환에 도움을 주는 크랜베리와 장관환경과 배변상태 개선을 지원하는 프리바이오틱 성분인 이눌린을 첨가했다. 특히 28년 간 펫푸드\n",
            "   를 만들어 일본에 수출해 온 동원FB가 국내에서 직접 만든 제품으로 믿을 수 있다. win5858@fnnews.com 김성원 기자\n",
            "[Predict: Answer] 동원FB의 펫푸드 전문 브랜드 뉴트리플랜 | 0:22\n",
            "[True: Context]\n",
            "   동원FB의 펫푸드 전문 브랜드 뉴트리플랜이 국내 최초 참치알을 넣어 만든 애묘 습식 파우치 뉴트리플랜 모이스트루 4종(사진)을 출시했다고 21일 밝혔다.\n",
            "    동원FB는 최근 약 30억 원을 투자해 국내 창원공장에 펫푸드 생산을 위한 라인을 증설했다. 증설된 라인에서는 참치와 펫푸드 노하우를 활용한 다양한 애\n",
            "   묘, 애견용 펫푸드를 선보일 예정이다. 그 첫 번째 시리즈가 국내 최초로 참치알을 활용해 만든 애묘용 습식파우치 모이스트루 4종(참치, 참치와 멸치, 참\n",
            "   치와 닭고기, 참치와 연어)이다. 뉴트리플랜 모이스트루 4종은 육식동물 고양이의 건강한 습식 습관을 위한 고급 파우치 제품이다. 필수 아미노산인 타우린과\n",
            "    아르기닌을 다량 함유하고 있는 참치 붉은 살과 단백질, 오메가-3 지방산 및 미네랄이 풍부하며 기호성이 높은 참치알을 담았다. 또한 고양이의 하부요로기\n",
            "    질환에 도움을 주는 크랜베리와 장관환경과 배변상태 개선을 지원하는 프리바이오틱 성분인 이눌린을 첨가했다. 특히 28년 간 펫푸드를 만들어 일본에 수출해\n",
            "    온 \u001b[1m\u001b[34m동원FB\u001b[0m가 국내에서 직접 만든 제품으로 믿을 수 있다. win5858@fnnews.com 김성원 기자\n",
            "[True: Answer] 동원FB | 513:517\n",
            "\n",
            "\u001b[1m[Question] 동원FB가 새로 증설된 펫푸드 생산라인에서 선보인 첫 번째 시리즈는 뭐야?\u001b[0m\n",
            "[Predict: Context]\n",
            "   동원FB의 펫푸드 전문 브랜드 뉴트리플랜이 국내 최초 참치알을 넣어 만든 애묘 습식 파우치 뉴트리플랜 모이스트루 4종(사진)을 출시했다고 21일 밝혔다.\n",
            "    동원FB는 최근 약 30억 원을 투자해 국내 창원공장에 펫푸드 생산을 위한 라인을 증설했다. 증설된 라인에서는 참치와 펫푸드 노하우를 활용한 다양한 애\n",
            "   묘, 애견용 펫푸드를 선보일 예정이다. 그 첫 번째 시리즈가 \u001b[1m\u001b[31m국내 최초로 참치알을 활용해 만든 애묘용 습식파우치 모이스트루 4종(참치, \n",
            "   참치와 멸치, 참치와 닭고기, 참치와 연어)\u001b[0m이다. 뉴트리플랜 모이스트루 4종은 육식동물 고양이의 건강한 습식 습관을 위한 고급 파우치 제품이다. \n",
            "   필수 아미노산인 타우린과 아르기닌을 다량 함유하고 있는 참치 붉은 살과 단백질, 오메가-3 지방산 및 미네랄이 풍부하며 기호성이 높은 참치알을 담았다. \n",
            "   또한 고양이의 하부요로기 질환에 도움을 주는 크랜베리와 장관환경과 배변상태 개선을 지원하는 프리바이오틱 성분인 이눌린을 첨가했다. 특히 28년 간 펫푸드\n",
            "   를 만들어 일본에 수출해 온 동원FB가 국내에서 직접 만든 제품으로 믿을 수 있다. win5858@fnnews.com 김성원 기자\n",
            "[Predict: Answer] 국내 최초로 참치알을 활용해 만든 애묘용 습식파우치 모이스트루 4종(참치, 참치와 멸치, 참치와 닭고기, 참치와 연어) | 204:270\n",
            "[True: Context]\n",
            "   동원FB의 펫푸드 전문 브랜드 뉴트리플랜이 국내 최초 참치알을 넣어 만든 애묘 습식 파우치 뉴트리플랜 모이스트루 4종(사진)을 출시했다고 21일 밝혔다.\n",
            "    동원FB는 최근 약 30억 원을 투자해 국내 창원공장에 펫푸드 생산을 위한 라인을 증설했다. 증설된 라인에서는 참치와 펫푸드 노하우를 활용한 다양한 애\n",
            "   묘, 애견용 펫푸드를 선보일 예정이다. 그 첫 번째 시리즈가 국내 최초로 참치알을 활용해 만든 애묘용 습식파우치 모이스트루 4종(참치, 참치와 멸치, 참\n",
            "   치와 닭고기, 참치와 연어)이다. \u001b[1m\u001b[34m뉴트리플랜 모이스트루 4종은 육식동물 고양이의 건강한 습식 습관을 위한 고급 파우치 제품이다\u001b[0m. \n",
            "   필수 아미노산인 타우린과 아르기닌을 다량 함유하고 있는 참치 붉은 살과 단백질, 오메가-3 지방산 및 미네랄이 풍부하며 기호성이 높은 참치알을 담았다. \n",
            "   또한 고양이의 하부요로기 질환에 도움을 주는 크랜베리와 장관환경과 배변상태 개선을 지원하는 프리바이오틱 성분인 이눌린을 첨가했다. 특히 28년 간 펫푸드\n",
            "   를 만들어 일본에 수출해 온 동원FB가 국내에서 직접 만든 제품으로 믿을 수 있다. win5858@fnnews.com 김성원 기자\n",
            "[True: Answer] 뉴트리플랜 모이스트루 4종은 육식동물 고양이의 건강한 습식 습관을 위한 고급 파우치 제품이다 | 274:325\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}