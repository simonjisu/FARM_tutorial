{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FARM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWSR3a5vxSGL",
        "outputId": "70d43e21-a241-4128-d90e-f896be518951"
      },
      "source": [
        "# For Colab: Install FARM\n",
        "!pip install torch==1.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install farm==0.5.0\n",
        "!pip install -U -q emoji soynlp\n",
        "!git clone https://github.com/e9t/nsmc"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (708.0MB)\n",
            "\u001b[K     |████████████████████████████████| 708.0MB 26kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement torch==1.8.0, but you'll have torch 1.6.0+cu101 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.6.0+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "Successfully installed torch-1.6.0+cu101\n",
            "Collecting farm==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/e4/2f47c850732a1d729e74add867e967f058370f29a313da05dc871ff8465e/farm-0.5.0-py3-none-any.whl (207kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<1.7,>1.5 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.6.0+cu101)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.36.2)\n",
            "Collecting flask-restplus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/a6/b17c848771f96ad039ad9e3ea275e842a16c39c4f3eb9f60ee330b20b6c2/flask_restplus-0.13.0-py2.py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 13.2MB/s \n",
            "\u001b[?25hCollecting flask-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.3.3)\n",
            "Collecting mlflow==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/ec/8c9448968d4662e8354b9c3a62e635f8929ed507a45af3d9fdb84be51270/mlflow-1.0.0-py3-none-any.whl (47.7MB)\n",
            "\u001b[K     |████████████████████████████████| 47.7MB 57kB/s \n",
            "\u001b[?25hCollecting dotmap==1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/eb/ee5f0358a9e0ede90308d8f34e697e122f191c2702dc4f614eca7770b1eb/dotmap-1.3.0-py3-none-any.whl\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/bd/3f9cc87a8faa561903644ec6ef7e7e408ca3640e77c5944124ad6adbaecd/boto3-1.17.39-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (54.1.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (4.41.1)\n",
            "Collecting transformers==3.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 42.9MB/s \n",
            "\u001b[?25hCollecting seqeval==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Collecting Werkzeug==0.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/e4/a859d2fe516f466642fa5c6054fd9646271f9da26b0cac0d2f37fc858c8f/Werkzeug-0.16.1-py2.py3-none-any.whl (327kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 39.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (5.4.8)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.4.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch<1.7,>1.5->farm==0.5.0) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch<1.7,>1.5->farm==0.5.0) (0.16.0)\n",
            "Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from flask-restplus->farm==0.5.0) (1.15.0)\n",
            "Collecting aniso8601>=0.82\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/04/e97c12dc034791d7b504860acfcdd2963fa21ae61eaca1c9d31245f812c3/aniso8601-9.0.1-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from flask-restplus->farm==0.5.0) (2.6.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from flask-restplus->farm==0.5.0) (2018.9)\n",
            "Collecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl\n",
            "Collecting docker>=3.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/22/410313ad554477e87ec406d38d85f810e61ddb0d2fc44e64994857476de9/docker-4.4.4-py2.py3-none-any.whl (147kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 42.1MB/s \n",
            "\u001b[?25hCollecting gunicorn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5b/0d1f0296485a6af03366604142ea8f19f0833894db3512a40ed07b2a56dd/gunicorn-20.1.0.tar.gz (370kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (0.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (3.12.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.1.5)\n",
            "Collecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 39.0MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/a4/97eb6273839655cac14947986fa7a5935350fcfd4fff872e9654264c82d8/alembic-1.5.8-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 40.6MB/s \n",
            "\u001b[?25hCollecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/04/377418ac1e530ce2a196b54c6552c018fdf1fe776718053efb1f216bffcd/simplejson-3.17.2-cp37-cp37m-manylinux2010_x86_64.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 30.9MB/s \n",
            "\u001b[?25hCollecting databricks-cli>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/af/631375abc29e59cedfa4467a5f7755503ba19898890751e1f2636ef02f92/databricks-cli-0.14.3.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (7.1.2)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (0.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (3.13)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.3.23)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (2.8.1)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.2MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.39\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/ad/abdc982cb695a20764df007a2d7cb0ac8964c9591fd014006e40334e4a74/botocore-1.20.39-py2.py3-none-any.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->farm==0.5.0) (0.22.2.post1)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/26/c02ba92ecb8b780bdae4a862d351433c2912fe49469dac7f87a5c85ccca6/tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 43.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 35.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (2019.12.20)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.12->farm==0.5.0) (2.4.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->farm==0.5.0) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->farm==0.5.0) (2.11.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (3.0.4)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.0->mlflow==1.0.0->farm==0.5.0) (0.8.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->farm==0.5.0) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3.1->farm==0.5.0) (2.4.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.12->farm==0.5.0) (2.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->farm==0.5.0) (1.1.1)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: seqeval, gunicorn, databricks-cli, sacremoses\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp37-none-any.whl size=7424 sha256=f21afe05cf3de75dfe8b472041b0ea6af761c4d45c94446576c20f9851875826\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "  Building wheel for gunicorn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gunicorn: filename=gunicorn-20.1.0-cp37-none-any.whl size=78918 sha256=fbea069490262ae31e2a5e6494bf7d911d98ad8fa34a6c89b6ec64b6c973ef28\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/ea/e2/698dde91d46e32a449e60f785a91954f67f72fea8890bb1072\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-cp37-none-any.whl size=100557 sha256=791d2a63d334131d22f4d9c8bcdb57f3faa31870f06343f9d8219f603a96288b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/24/f3/34d8e3964dac4ba849d844273c49a679111b00d5799ebb934a\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=852578994f9d29fc4570c59e9babff76cc92220bf0ee13cdc466b459edae3ffb\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built seqeval gunicorn databricks-cli sacremoses\n",
            "\u001b[31mERROR: botocore 1.20.39 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: aniso8601, flask-restplus, flask-cors, querystring-parser, websocket-client, docker, gunicorn, smmap, gitdb, gitpython, python-editor, Mako, alembic, simplejson, databricks-cli, mlflow, dotmap, jmespath, botocore, s3transfer, boto3, tokenizers, sentencepiece, sacremoses, transformers, seqeval, Werkzeug, farm\n",
            "  Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "Successfully installed Mako-1.1.4 Werkzeug-0.16.1 alembic-1.5.8 aniso8601-9.0.1 boto3-1.17.39 botocore-1.20.39 databricks-cli-0.14.3 docker-4.4.4 dotmap-1.3.0 farm-0.5.0 flask-cors-3.0.10 flask-restplus-0.13.0 gitdb-4.0.7 gitpython-3.1.14 gunicorn-20.1.0 jmespath-0.10.0 mlflow-1.0.0 python-editor-1.0.4 querystring-parser-1.2.4 s3transfer-0.3.6 sacremoses-0.0.43 sentencepiece-0.1.95 seqeval-0.0.12 simplejson-3.17.2 smmap-4.0.0 tokenizers-0.8.1rc2 transformers-3.3.1 websocket-client-0.58.0\n",
            "\u001b[K     |████████████████████████████████| 133kB 11.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 419kB 11.2MB/s \n",
            "\u001b[?25hCloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 19.26 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Checking out files: 100% (14737/14737), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM4H-pbDL_XC"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import emoji\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from soynlp.normalizer import repeat_normalize\n",
        "\n",
        "def read_data(path:str, header=None):\n",
        "    return pd.read_csv(path, sep='\\t', header=header)\n",
        "\n",
        "def clean(x):\n",
        "    emojis = ''.join(emoji.UNICODE_EMOJI.keys())\n",
        "    pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-힣{emojis}]+')\n",
        "    url_pattern = re.compile(\n",
        "        r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
        "    \n",
        "    x = pattern.sub(' ', x)\n",
        "    x = url_pattern.sub('', x)\n",
        "    x = x.strip()\n",
        "    x = repeat_normalize(x, num_repeats=2)\n",
        "    return x\n",
        "\n",
        "def preprocess_dataframe(df:pd.DataFrame):\n",
        "    r\"\"\"\n",
        "    Changed the code\n",
        "    source from: https://colab.research.google.com/drive/1IPkZo1Wd-DghIOK6gJpcb0Dv4_Gv2kXB\n",
        "    \"\"\"\n",
        "\n",
        "    label_dict = {0:\"bad\", 1:\"good\"}\n",
        "    df['document'] = df['document'].apply(lambda x: clean(str(x)))\n",
        "    df['label'] = df['label'].apply(label_dict.get)\n",
        "    return df\n",
        "\n",
        "df_train = preprocess_dataframe(read_data(\"./nsmc/ratings_train.txt\", header=0))\n",
        "df_test = preprocess_dataframe(read_data(\"./nsmc/ratings_test.txt\", header=0))\n",
        "df_train.loc[:, [\"label\", \"document\"]].to_csv(\"./nsmc/train.tsv\", sep=\"\\t\", index=False)\n",
        "df_test.loc[:, [\"label\", \"document\"]].to_csv(\"./nsmc/test.tsv\", sep=\"\\t\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-PcIhBaB3-E",
        "outputId": "53cc078d-cd62-4fe0-fef2-68aa38fe97bf"
      },
      "source": [
        "!ls nsmc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "code\t\t  ratings_train.txt  raw\tsynopses.json\n",
            "ratings_test.txt  ratings.txt\t     README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeTtCfRkyxVJ",
        "outputId": "50e7f3f7-439b-4069-f140-c01c6963289d"
      },
      "source": [
        "import sys\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.data_handler.data_silo import DataSilo\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import TextClassificationHead\n",
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import MLFlowLogger\n",
        "\n",
        "repo_path = Path().absolute().parent\n",
        "sys.path.append(str(repo_path))\n",
        "\n",
        "ml_logger = MLFlowLogger(tracking_uri=\"https://public-mlflow.deepset.ai/\")\n",
        "ml_logger.init_experiment(experiment_name=\"FARM_tutorial\", run_name=\"NSMC\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Devices available: {}\".format(device))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/29/2021 08:08:42 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS3WaV8YMJmh"
      },
      "source": [
        "<center><img src=\"https://drive.google.com/uc?id=1hbtUClFoXg45IbViZoFRLnnDGVlr9Dlb\" alt=\"Fine-tuning\" width=\"30%\" height=\"30%\"></center>\n",
        "\n",
        "# FARM\n",
        "\n",
        "> Framework for Adapting Representation Models\n",
        "\n",
        "Fine-tuning에 최적화된 도구\n",
        "\n",
        "## Core Features\n",
        "\n",
        "- **Easy fine-tuning of language models** to your task and domain language\n",
        "- **Speed**: AMP(Automatic Mixed Precision) optimizers (~35% faster) and parallel preprocessing (16 CPU cores => ~16x faster)\n",
        "- **Modular design** of language models and prediction heads\n",
        "- Switch between heads or combine them for **multitask learning**\n",
        "- **Full Compatibility** with HuggingFace Transformers' models and model hub\n",
        "- **Smooth upgrading** to newer language models\n",
        "- Integration of **custom datasets** via Processor class\n",
        "- Powerful **experiment tracking** & execution\n",
        "- **Checkpointing & Caching** to resume training and reduce costs with spot instances\n",
        "- Simple **deployment** and **visualization** to showcase your model\n",
        "\n",
        "<details>\n",
        "<summary> AMP </summary>\n",
        "\n",
        "**Reference**\n",
        "- https://github.com/NVIDIA/apex\n",
        "- https://forums.fast.ai/t/mixed-precision-training/20720\n",
        "\n",
        "**mixed precision training이란**\n",
        "- 처리 속도를 높이기 위한 FP16(16bit floating point)연산과 정확도 유지를 위한 FP32 연산을 섞어 학습하는 방법\n",
        "- Tensor Core를 활용한 FP16연산을 이용하면 FP32연산 대비 절반의 메모리 사용량과 8배의 연산 처리량 & 2배의 메모리 처리량 효과가 있다\n",
        "</details>\n",
        "\n",
        "## Fine-tuning Process\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?id=1j9pn8Lpg7sy6S8Ubvq3E7JLWf28KvRt4\" alt=\"Fine-tuning\" width=\"50%\" height=\"50%\" align=\"center\"></center>\n",
        "\n",
        "Fine-tuning Processing 그림과 같이 진행된다.\n",
        "\n",
        "* Load Data: 데이터를 알맞는 형식(json, csv 등)으로 불러온다.\n",
        "* Create Dataset: 데이터세트(Dataset) 만들기\n",
        "    * Tokenization: 텍스트를 토큰으로 나누고, 단어장(vocab)을 생성한다.\n",
        "    * ToTensor: vocab에 해당하는 단어를 수치화하는 과정 (`input_ids` in transformers)\n",
        "    * Attention Mask: 패딩계산을 피하기 위해 Attention 해야할 토큰만 masking(`attention_mask` in transformers)\n",
        "* Create Dataloader: 훈련, 평가시 배치크기 단위로 데이터를 불러오는 객체\n",
        "* Create Model:\n",
        "    * Pretrained Language Model: 대량의 텍스트 데이터로 사전에 훈련된 모델\n",
        "    * Fine-tuninig Layer: Downstream Task에 맞춰서 변화\n",
        "* Train Model\n",
        "* Eval Model\n",
        "* Inference\n",
        "\n",
        "# NSMC 데이터 세트로 알아보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hSnf1TDMJEB"
      },
      "source": [
        "# from src import read_data\n",
        "\n",
        "DATA_PATH = repo_path / \"nsmc\"\n",
        "df = read_data(DATA_PATH / \"train.tsv\", header=0)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsQKHSPlMovO"
      },
      "source": [
        "## Processor & Data Silo\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?id=1XCc0AJpPBMFcC81NW0A6w0mpswZ2KU7h\" alt=\"Fine-tuning\" width=\"60%\" height=\"50%\" align=\"center\"></center>\n",
        "\n",
        "* **Processor**는 file 혹은 request를 PyTorch Datset로 만들어 주는 역할\n",
        "* **Data Silo**는 train, dev, test sets를 관리하고, Processor의 function들 이용해 각 set를 DataLoader로 변환한다.\n",
        "    * **Samples**, **SampleBasket**은 raw document를 관리하는 객체이며 tokenized, features등 데이터를 저장하고 있다. 이렇게 하는 이유는 하나의 소스 텍스트(raw text)에서 여러개의 샘플을 생성할 수도 있기 때문이다(e.g. QA task)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuQEtIvNTI5V"
      },
      "source": [
        "PRETRAINED_MODEL_NAME_OR_PATH = \"beomi/kcbert-base\"  # Reference: https://github.com/Beomi/KcBERT\n",
        "MAX_LENGTH = 300\n",
        "LABEL_LIST = [\"bad\", \"good\"]\n",
        "TRAIN_FILE = \"train.tsv\"\n",
        "TEST_FILE = \"test.tsv\"\n",
        "TASK_TYPE = \"text_classification\"\n",
        "\n",
        "tokenizer = Tokenizer.load(\n",
        "    pretrained_model_name_or_path=PRETRAINED_MODEL_NAME_OR_PATH,\n",
        "    do_lower_case=False,\n",
        ")\n",
        "\n",
        "processor = TextClassificationProcessor(\n",
        "    tokenizer=tokenizer,\n",
        "    train_filename=TRAIN_FILE,\n",
        "    test_filename=TEST_FILE,\n",
        "    dev_split=0.1,\n",
        "    header=0,\n",
        "    max_seq_len=MAX_LENGTH,\n",
        "    data_dir=str(DATA_PATH),\n",
        "    label_list=LABEL_LIST,\n",
        "    metric=\"acc\",\n",
        "    label_column_name=\"label\",\n",
        "    text_column_name=\"document\",\n",
        "    delimiter=\"\\t\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBqy3S68OIX9"
      },
      "source": [
        "<center><img src=\"https://drive.google.com/uc?id=1DVPT_Rjv_SI4ggJZzqfPh0MgsMa1Q9El\" alt=\"Fine-tuning\" width=\"100%\" height=\"50%\" align=\"center\"></center>\n",
        "\n",
        "```plaintext\n",
        "03/28/2021 22:12:15 - INFO - farm.data_handler.processor -   \n",
        "\n",
        "      .--.        _____                       _      \n",
        "    .'_\\/_'.     / ____|                     | |     \n",
        "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
        "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
        "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
        "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
        "   (/\\||/                             |_|           \n",
        "______\\||/___________________________________________                     \n",
        "\n",
        "ID: 437-0\n",
        "Clear Text: \n",
        " \ttext_classification_label: good\n",
        " \ttext: 이 영화를 보고 두통이 나았습니다. ㅠ ㅠ\n",
        "Tokenized: \n",
        " \ttokens: ['이', '영화를', '보고', '두', '##통이', '나', '##았습니다', '.', '[UNK]', '[UNK]']\n",
        " \toffsets: [0, 2, 6, 9, 10, 13, 14, 18, 20, 22]\n",
        " \tstart_of_word: [True, True, True, True, False, True, False, False, True, True]\n",
        "Features: \n",
        " \tinput_ids: [2, 2451, 25833, 8198, 917, 11765, 587, 21809, 17, 1,\n",
        "      1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        " \ttext_classification_label_ids: [1]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ_tuLHRTgGb"
      },
      "source": [
        "## Modeling Layers: AdaptiveModel = LanguageModel + PredictionHead\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?id=1OLWdr8rh7ucpF9t55gzVeMawMBJbRiEC\" alt=\"Fine-tuning\" width=\"60%\" height=\"50%\" align=\"center\"></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60M4IEtWTitY"
      },
      "source": [
        "# LanguageModel: Build pretrained language model\n",
        "EMBEDS_DROPOUT_PROB = 0.1\n",
        "\n",
        "language_model = LanguageModel.load(PRETRAINED_MODEL_NAME_OR_PATH, language=\"korean\")\n",
        "# PredictionHead: Build predictor layer\n",
        "prediction_head = TextClassificationHead(\n",
        "    num_labels=len(LABEL_LIST), \n",
        "    class_weights=data_silo.calculate_class_weights(\n",
        "        task_name=TASK_NAME\n",
        "    )\n",
        ")\n",
        "model = AdaptiveModel(\n",
        "    language_model=language_model,\n",
        "    prediction_heads=[prediction_head],\n",
        "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
        "    lm_output_types=[\"per_sequence\"],\n",
        "    device=device\n",
        ")\n",
        "\n",
        "for k, v in model.named_children():\n",
        "    print(k)\n",
        "print(model.dropout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmMLVGnpTqxB"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "bert = BertForSequenceClassification.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "print(bert.dropout)\n",
        "print(bert.classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbvskPXaTlGp"
      },
      "source": [
        "<center><img src=\"https://drive.google.com/uc?id=1bD54igqAn7T96gDCFZ2uxzFHpZIL5GOh\" alt=\"Fine-tuning\" width=\"60%\" height=\"50%\" align=\"center\"></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mkJ4fF9uQlO",
        "outputId": "1e69beaa-a58d-40a1-d0d4-c4d1f425333d"
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "bert = BertForSequenceClassification.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "print(bert.dropout)\n",
        "print(bert.classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dropout(p=0.1, inplace=False)\n",
            "Linear(in_features=768, out_features=2, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA3QoKnvTz17"
      },
      "source": [
        "## TASK Supported\n",
        "\n",
        "|Task|BERT|RoBERTa*|XLNet|ALBERT|DistilBERT|XLMRoBERTa|ELECTRA|MiniLM|\n",
        "|---|---|---|---|---|---|---|---|---|\n",
        "|Text classification|x|x|x|x|x|x|x|x|\n",
        "|NER|x|x|x|x|x|x|x|x|\n",
        "|Question Answering|x|x|x|x|x|x|x|x|\n",
        "|Language Model Fine-tuning|x||||||||\n",
        "|Text Regression|x|x|x|x|x|x|x|x|\n",
        "|Multilabel Text classif.|x|x|x|x|x|x|x|x|\n",
        "|Extracting embeddings|x|x|x|x|x|x|x|x|\n",
        "|LM from scratch|x||||||||\n",
        "|Text Pair Classification|x|x|x|x|x|x|x|x|\n",
        "|Passage Ranking|x|x|x|x|x|x|x|x|\n",
        "|Document retrieval (DPR)|x|x||x|x|x|x|x|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnIPo08yw3--",
        "outputId": "b66c4a4a-e9ec-4d80-f873-0a64a357dd8d"
      },
      "source": [
        "for k, v in model.named_children():\n",
        "    print(k)\n",
        "print(model.dropout)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "language_model\n",
            "prediction_heads\n",
            "dropout\n",
            "Dropout(p=0.09, inplace=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4OQGFc3T7eY"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLUejzaqUBoe"
      },
      "source": [
        "parser = argparse.ArgumentParser(description=\"run farm\")\n",
        "parser.add_argument(\"--tracking_uri\", type=str, default=\"https://public-mlflow.deepset.ai/\",\n",
        "    help=\"MLFlow - tracking uri \")\n",
        "parser.add_argument(\"--experiment_name\", type=str, default=\"FARM_tutorial\",\n",
        "    help=\"MLFlow - experiment name\")\n",
        "parser.add_argument(\"--run_name\", type=str, default=\"NSMC\",\n",
        "    help=\"MLFlow - run name\")\n",
        "parser.add_argument(\"--pretrained_model_name_or_path\", type=str, default=\"beomi/kcbert-base\",\n",
        "    help=\"Tokenizer, LanguageModel - pretrained model name\")\n",
        "\n",
        "parser.add_argument(\"--train_filename\", type=str, default=\"train.tsv\",\n",
        "    help=\"Processor - train file name\")\n",
        "parser.add_argument(\"--test_filename\", type=str, default=\"test.tsv\",\n",
        "    help=\"Processor - test file name\")\n",
        "parser.add_argument(\"--max_seq_len\", type=int, default=150,\n",
        "    help=\"Processor - max sequence lenght of tokens\")\n",
        "parser.add_argument(\"--data_dir\",  type=str, default=\"./nsmc/\",\n",
        "    help=\"Processor - data directory\")\n",
        "parser.add_argument(\"--label_list\", nargs=\"*\", default=[\"bad\", \"good\"],\n",
        "    help=\"Processor - label list with string\")\n",
        "parser.add_argument(\"--metric\",  type=str, default=\"acc\",\n",
        "    help=\"Processor - acc or f1_macro\")\n",
        "parser.add_argument(\"--label_column_name\",  type=str, default=\"label\",\n",
        "    help=\"Processor - label column name\")\n",
        "parser.add_argument(\"--text_column_name\",  type=str, default=\"document\",\n",
        "    help=\"Processor - text column name\")\n",
        "parser.add_argument(\"--ckpt_path\",  type=str, default=\"./ckpt\",\n",
        "    help=\"Processor - checkpoint to save processor\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=256,\n",
        "    help=\"DataSilo - train batch size\")\n",
        "parser.add_argument(\"--eval_batch_size\", type=int, default=256,\n",
        "    help=\"DataSilo - eval batch size\")\n",
        "parser.add_argument(\"--embeds_dropout_prob\", type=float, default=0.1,\n",
        "    help=\"AdaptiveModel - The probability that a value in the embeddings returned by the language model will be zeroed.\")\n",
        "parser.add_argument(\"--learning_rate\", type=float, default=2e-5,\n",
        "    help=\"initialize_optimizer - learning rate\")\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=1,\n",
        "    help=\"initialize_optimizer - number of epochs\")\n",
        "parser.add_argument(\"--n_gpu\", type=int, default=4,\n",
        "    help=\"Trainer - number of gpus\")\n",
        "parser.add_argument(\"--checkpoint_root_dir\", type=str, default=\"./ckpt\",\n",
        "    help=\"Trainer - checkpoint root directory\")\n",
        "parser.add_argument(\"--checkpoints_to_keep\", type=int, default=3,\n",
        "    help=\"Trainer - number of checkpoint to keep\")\n",
        "parser.add_argument(\"--checkpoint_every\", type=int, default=200,\n",
        "    help=\"Trainer - checkpoint every\")\n",
        "parser.add_argument(\"--evaluate_every\", type=int, default=200,\n",
        "    help=\"Trainer - evaluate steps\")\n",
        "args = parser.parse_known_args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcmE75TkwnVi",
        "outputId": "36e96fda-8298-4da7-adba-fa27f86d2297"
      },
      "source": [
        "LEARNING_RATE = 2e-5\n",
        "N_EPOCHS = 1\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=N_EPOCHS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/26/2021 09:12:17 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 2e-05}'\n",
            "03/26/2021 09:12:18 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "03/26/2021 09:12:18 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 1674.8000000000002, 'num_training_steps': 16748}'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaHFGsJcwukH"
      },
      "source": [
        "N_GPU = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    data_silo=data_silo,\n",
        "    epochs=N_EPOCHS,\n",
        "    n_gpu=N_GPU,\n",
        "    lr_schedule=lr_schedule,\n",
        "    device=device, \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8UZm37gxv5h",
        "outputId": "82f97f5b-899f-4e87-9d64-0bd7649203e2"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Mar 26 09:12:26 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    23W /  75W |   1069MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBxGXS-Bxyay",
        "outputId": "b231186c-9f47-41b1-a4a4-35bdc5491d83"
      },
      "source": [
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/26/2021 09:12:29 - INFO - farm.train -   \n",
            " \n",
            "\n",
            "          &&& &&  & &&             _____                   _             \n",
            "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
            "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
            "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
            "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
            "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
            " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
            "     &&     \\|||                                                   |___/\n",
            "             |||\n",
            "             |||\n",
            "             |||\n",
            "       , -=-~  .-^- _\n",
            "              `\n",
            "\n",
            "Train epoch 0/0 (Cur. train loss: 0.5005):   1%|          | 100/16748 [00:36<1:28:20,  3.14it/s]\n",
            "Evaluating:   0%|          | 0/1942 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6%|▋         | 125/1942 [00:10<02:25, 12.49it/s]\u001b[A\n",
            "Evaluating:  13%|█▎        | 250/1942 [00:20<02:15, 12.49it/s]\u001b[A\n",
            "Evaluating:  19%|█▉        | 376/1942 [00:30<02:05, 12.49it/s]\u001b[A\n",
            "Evaluating:  26%|██▌       | 502/1942 [00:40<01:55, 12.45it/s]\u001b[A\n",
            "Evaluating:  32%|███▏      | 626/1942 [00:50<01:46, 12.39it/s]\u001b[A\n",
            "Evaluating:  39%|███▊      | 749/1942 [01:00<01:36, 12.32it/s]\u001b[A\n",
            "Evaluating:  45%|████▍     | 871/1942 [01:10<01:27, 12.26it/s]\u001b[A\n",
            "Evaluating:  51%|█████     | 993/1942 [01:20<01:17, 12.20it/s]\u001b[A\n",
            "Evaluating:  57%|█████▋    | 1114/1942 [01:30<01:08, 12.16it/s]\u001b[A\n",
            "Evaluating:  64%|██████▎   | 1235/1942 [01:40<00:58, 12.11it/s]\u001b[A\n",
            "Evaluating:  70%|██████▉   | 1355/1942 [01:50<00:48, 12.06it/s]\u001b[A\n",
            "Evaluating:  76%|███████▌  | 1475/1942 [02:00<00:38, 12.03it/s]\u001b[A\n",
            "Evaluating:  82%|████████▏ | 1596/1942 [02:10<00:28, 12.02it/s]\u001b[A\n",
            "Evaluating:  88%|████████▊ | 1717/1942 [02:21<00:18, 12.03it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 1942/1942 [02:39<00:00, 12.16it/s]\n",
            "03/26/2021 09:15:46 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "03/26/2021 09:15:46 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "03/26/2021 09:15:47 - INFO - farm.eval -   loss: 0.6142998443219222\n",
            "03/26/2021 09:15:47 - INFO - farm.eval -   task_name: text_classification\n",
            "03/26/2021 09:15:48 - INFO - farm.eval -   acc: 0.6101062117798519\n",
            "03/26/2021 09:15:48 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         bad     0.8516    0.2741    0.4147      7829\n",
            "        good     0.5633    0.9515    0.7077      7706\n",
            "\n",
            "    accuracy                         0.6101     15535\n",
            "   macro avg     0.7075    0.6128    0.5612     15535\n",
            "weighted avg     0.7086    0.6101    0.5600     15535\n",
            "\n",
            "Train epoch 0/0 (Cur. train loss: 0.4918):   1%|          | 200/16748 [03:54<1:27:40,  3.15it/s]\n",
            "Evaluating:   0%|          | 0/1942 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 120/1942 [00:10<02:31, 11.99it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 240/1942 [00:20<02:22, 11.91it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 358/1942 [00:30<02:14, 11.78it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 479/1942 [00:40<02:03, 11.84it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 600/1942 [00:50<01:52, 11.90it/s]\u001b[A\n",
            "Evaluating:  37%|███▋      | 721/1942 [01:00<01:42, 11.94it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 842/1942 [01:10<01:31, 11.97it/s]\u001b[A\n",
            "Evaluating:  50%|████▉     | 963/1942 [01:20<01:21, 11.99it/s]\u001b[A\n",
            "Evaluating:  56%|█████▌    | 1084/1942 [01:30<01:11, 11.99it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 1205/1942 [01:40<01:01, 12.00it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 1326/1942 [01:51<00:51, 11.99it/s]\u001b[A\n",
            "Evaluating:  75%|███████▍  | 1447/1942 [02:01<00:41, 12.00it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 1568/1942 [02:11<00:31, 12.00it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 1689/1942 [02:21<00:21, 12.01it/s]\u001b[A\n",
            "Evaluating:  93%|█████████▎| 1810/1942 [02:31<00:10, 12.02it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 1942/1942 [02:42<00:00, 11.96it/s]\n",
            "03/26/2021 09:19:07 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "03/26/2021 09:19:07 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "03/26/2021 09:19:07 - INFO - farm.eval -   loss: 0.4708765826656537\n",
            "03/26/2021 09:19:07 - INFO - farm.eval -   task_name: text_classification\n",
            "03/26/2021 09:19:07 - INFO - farm.eval -   acc: 0.7795300933376247\n",
            "03/26/2021 09:19:07 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         bad     0.8420    0.6924    0.7599      7829\n",
            "        good     0.7353    0.8680    0.7962      7706\n",
            "\n",
            "    accuracy                         0.7795     15535\n",
            "   macro avg     0.7887    0.7802    0.7781     15535\n",
            "weighted avg     0.7891    0.7795    0.7779     15535\n",
            "\n",
            "Train epoch 0/0 (Cur. train loss: 0.7000):   2%|▏         | 300/16748 [07:13<1:27:01,  3.15it/s]\n",
            "Evaluating:   0%|          | 0/1942 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 120/1942 [00:10<02:32, 11.96it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 240/1942 [00:20<02:22, 11.94it/s]\u001b[A\n",
            "Evaluating:  19%|█▊        | 360/1942 [00:30<02:14, 11.75it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 480/1942 [00:40<02:03, 11.82it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 601/1942 [00:50<01:52, 11.88it/s]\u001b[A\n",
            "Evaluating:  37%|███▋      | 722/1942 [01:00<01:42, 11.92it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 843/1942 [01:10<01:31, 11.95it/s]\u001b[A\n",
            "Evaluating:  50%|████▉     | 964/1942 [01:20<01:21, 11.97it/s]\u001b[A\n",
            "Evaluating:  56%|█████▌    | 1085/1942 [01:31<01:11, 11.98it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 1205/1942 [01:41<01:01, 11.97it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 1325/1942 [01:51<00:51, 11.97it/s]\u001b[A\n",
            "Evaluating:  74%|███████▍  | 1445/1942 [02:01<00:41, 11.97it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 1565/1942 [02:11<00:31, 11.98it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 1685/1942 [02:21<00:21, 11.98it/s]\u001b[A\n",
            "Evaluating:  93%|█████████▎| 1805/1942 [02:31<00:11, 11.98it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 1942/1942 [02:42<00:00, 11.94it/s]\n",
            "03/26/2021 09:22:27 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 300 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "03/26/2021 09:22:27 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "03/26/2021 09:22:27 - INFO - farm.eval -   loss: 0.5492911689623706\n",
            "03/26/2021 09:22:27 - INFO - farm.eval -   task_name: text_classification\n",
            "03/26/2021 09:22:28 - INFO - farm.eval -   acc: 0.7681364660444159\n",
            "03/26/2021 09:22:28 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         bad     0.6956    0.9599    0.8067      7829\n",
            "        good     0.9336    0.5733    0.7104      7706\n",
            "\n",
            "    accuracy                         0.7681     15535\n",
            "   macro avg     0.8146    0.7666    0.7585     15535\n",
            "weighted avg     0.8137    0.7681    0.7589     15535\n",
            "\n",
            "Train epoch 0/0 (Cur. train loss: 0.6046):   2%|▏         | 400/16748 [10:34<1:26:42,  3.14it/s]\n",
            "Evaluating:   0%|          | 0/1942 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 120/1942 [00:10<02:32, 11.95it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 240/1942 [00:20<02:23, 11.87it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 357/1942 [00:30<02:15, 11.73it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 477/1942 [00:40<02:04, 11.80it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 598/1942 [00:50<01:53, 11.86it/s]\u001b[A\n",
            "Evaluating:  37%|███▋      | 719/1942 [01:00<01:42, 11.90it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 840/1942 [01:10<01:32, 11.93it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 961/1942 [01:20<01:22, 11.95it/s]\u001b[A\n",
            "Evaluating:  56%|█████▌    | 1082/1942 [01:31<01:11, 11.96it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 1202/1942 [01:41<01:01, 11.96it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 1322/1942 [01:51<00:51, 11.96it/s]\u001b[A\n",
            "Evaluating:  74%|███████▍  | 1442/1942 [02:01<00:41, 11.96it/s]\u001b[A\n",
            "Evaluating:  80%|████████  | 1562/1942 [02:11<00:31, 11.97it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 1682/1942 [02:21<00:21, 11.97it/s]\u001b[A\n",
            "Evaluating:  93%|█████████▎| 1802/1942 [02:31<00:11, 11.98it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 1942/1942 [02:42<00:00, 11.93it/s]\n",
            "03/26/2021 09:25:48 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 400 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "03/26/2021 09:25:48 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "03/26/2021 09:25:48 - INFO - farm.eval -   loss: 0.4009998004114969\n",
            "03/26/2021 09:25:48 - INFO - farm.eval -   task_name: text_classification\n",
            "03/26/2021 09:25:48 - INFO - farm.eval -   acc: 0.8216285806243965\n",
            "03/26/2021 09:25:48 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         bad     0.7906    0.8789    0.8324      7829\n",
            "        good     0.8612    0.7634    0.8094      7706\n",
            "\n",
            "    accuracy                         0.8216     15535\n",
            "   macro avg     0.8259    0.8212    0.8209     15535\n",
            "weighted avg     0.8256    0.8216    0.8210     15535\n",
            "\n",
            "Train epoch 0/0 (Cur. train loss: 0.4204):   3%|▎         | 500/16748 [13:55<1:26:07,  3.14it/s]\n",
            "Evaluating:   0%|          | 0/1942 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 120/1942 [00:10<02:32, 11.94it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 240/1942 [00:20<02:22, 11.93it/s]\u001b[A\n",
            "Evaluating:  19%|█▊        | 360/1942 [00:30<02:12, 11.92it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 480/1942 [00:40<02:02, 11.92it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 601/1942 [00:50<01:52, 11.95it/s]\u001b[A\n",
            "Evaluating:  37%|███▋      | 722/1942 [01:00<01:41, 11.97it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 843/1942 [01:10<01:31, 11.99it/s]\u001b[A\n",
            "Evaluating:  50%|████▉     | 964/1942 [01:20<01:21, 11.99it/s]\u001b[A\n",
            "Evaluating:  56%|█████▌    | 1085/1942 [01:30<01:11, 11.99it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 1205/1942 [01:40<01:01, 11.97it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 1325/1942 [01:50<00:51, 11.98it/s]\u001b[A\n",
            "Evaluating:  74%|███████▍  | 1445/1942 [02:00<00:41, 11.97it/s]\u001b[A\n",
            "Evaluating:  81%|████████  | 1565/1942 [02:10<00:31, 11.98it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 1685/1942 [02:20<00:21, 11.98it/s]\u001b[A\n",
            "Evaluating:  93%|█████████▎| 1805/1942 [02:30<00:11, 11.97it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 1942/1942 [02:42<00:00, 11.97it/s]\n",
            "03/26/2021 09:29:07 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 500 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "03/26/2021 09:29:07 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "03/26/2021 09:29:08 - INFO - farm.eval -   loss: 0.43587411767921536\n",
            "03/26/2021 09:29:08 - INFO - farm.eval -   task_name: text_classification\n",
            "03/26/2021 09:29:08 - INFO - farm.eval -   acc: 0.8296749275828774\n",
            "03/26/2021 09:29:08 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         bad     0.8418    0.8153    0.8283      7829\n",
            "        good     0.8182    0.8443    0.8310      7706\n",
            "\n",
            "    accuracy                         0.8297     15535\n",
            "   macro avg     0.8300    0.8298    0.8297     15535\n",
            "weighted avg     0.8300    0.8297    0.8297     15535\n",
            "\n",
            "Train epoch 0/0 (Cur. train loss: 0.6015):   4%|▎         | 600/16748 [17:14<1:25:26,  3.15it/s]\n",
            "Evaluating:   0%|          | 0/1942 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 120/1942 [00:10<02:32, 11.94it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 240/1942 [00:20<02:22, 11.92it/s]\u001b[A\n",
            "Evaluating:  19%|█▊        | 360/1942 [00:30<02:12, 11.92it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 480/1942 [00:40<02:02, 11.92it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 600/1942 [00:50<01:52, 11.94it/s]\u001b[A\n",
            "Evaluating:  37%|███▋      | 720/1942 [01:00<01:42, 11.95it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 841/1942 [01:10<01:31, 11.97it/s]\u001b[A\n",
            "Evaluating:  50%|████▉     | 962/1942 [01:20<01:21, 11.98it/s]\u001b[A\n",
            "Evaluating:  56%|█████▌    | 1082/1942 [01:30<01:11, 11.98it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 1202/1942 [01:40<01:01, 11.97it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 1322/1942 [01:50<00:51, 11.96it/s]\u001b[A\n",
            "Evaluating:  74%|███████▍  | 1442/1942 [02:00<00:41, 11.96it/s]\u001b[A\n",
            "Evaluating:  80%|████████  | 1562/1942 [02:10<00:31, 11.96it/s]\u001b[A\n",
            "Evaluating:  87%|████████▋ | 1682/1942 [02:20<00:21, 11.96it/s]\u001b[A\n",
            "Evaluating:  93%|█████████▎| 1802/1942 [02:30<00:11, 11.97it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 1942/1942 [02:42<00:00, 11.96it/s]\n",
            "03/26/2021 09:32:27 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 600 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "03/26/2021 09:32:27 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "03/26/2021 09:32:27 - INFO - farm.eval -   loss: 0.4120800150008611\n",
            "03/26/2021 09:32:27 - INFO - farm.eval -   task_name: text_classification\n",
            "03/26/2021 09:32:28 - INFO - farm.eval -   acc: 0.8360476343739942\n",
            "03/26/2021 09:32:28 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         bad     0.8261    0.8545    0.8401      7829\n",
            "        good     0.8468    0.8173    0.8318      7706\n",
            "\n",
            "    accuracy                         0.8360     15535\n",
            "   macro avg     0.8365    0.8359    0.8359     15535\n",
            "weighted avg     0.8364    0.8360    0.8360     15535\n",
            "\n",
            "Train epoch 0/0 (Cur. train loss: 0.6128):   4%|▍         | 700/16748 [20:34<1:25:02,  3.15it/s]\n",
            "Evaluating:   0%|          | 0/1942 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 120/1942 [00:10<02:33, 11.90it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 240/1942 [00:20<02:24, 11.75it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 355/1942 [00:30<02:16, 11.67it/s]\u001b[A\n",
            "Evaluating:  24%|██▍       | 475/1942 [00:40<02:04, 11.74it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 595/1942 [00:50<01:54, 11.80it/s]\u001b[A\n",
            "Evaluating:  37%|███▋      | 715/1942 [01:00<01:43, 11.85it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 835/1942 [01:10<01:33, 11.88it/s]\u001b[A\n",
            "Evaluating:  49%|████▉     | 955/1942 [01:20<01:23, 11.89it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 1075/1942 [01:30<01:12, 11.89it/s]\u001b[A\n",
            "Evaluating:  62%|██████▏   | 1195/1942 [01:41<01:02, 11.89it/s]\u001b[A\n",
            "Evaluating:  68%|██████▊   | 1315/1942 [01:51<00:52, 11.90it/s]\u001b[A\n",
            "Evaluating:  74%|███████▍  | 1435/1942 [02:01<00:42, 11.90it/s]\u001b[A\n",
            "Evaluating:  80%|████████  | 1555/1942 [02:11<00:32, 11.90it/s]\u001b[A\n",
            "Evaluating:  86%|████████▋ | 1675/1942 [02:21<00:22, 11.90it/s]\u001b[A\n",
            "Evaluating:  92%|█████████▏| 1795/1942 [02:31<00:12, 11.91it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 1942/1942 [02:43<00:00, 11.86it/s]\n",
            "03/26/2021 09:35:48 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 700 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "03/26/2021 09:35:48 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "03/26/2021 09:35:49 - INFO - farm.eval -   loss: 0.41480645573058617\n",
            "03/26/2021 09:35:49 - INFO - farm.eval -   task_name: text_classification\n",
            "03/26/2021 09:35:49 - INFO - farm.eval -   acc: 0.8290312198261989\n",
            "03/26/2021 09:35:49 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         bad     0.7872    0.9055    0.8422      7829\n",
            "        good     0.8867    0.7514    0.8134      7706\n",
            "\n",
            "    accuracy                         0.8290     15535\n",
            "   macro avg     0.8370    0.8284    0.8278     15535\n",
            "weighted avg     0.8366    0.8290    0.8279     15535\n",
            "\n",
            "Train epoch 0/0 (Cur. train loss: 0.1388):   5%|▍         | 800/16748 [23:55<1:25:05,  3.12it/s]\n",
            "Evaluating:   0%|          | 0/1942 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6%|▌         | 119/1942 [00:10<02:33, 11.86it/s]\u001b[A\n",
            "Evaluating:  12%|█▏        | 238/1942 [00:20<02:23, 11.85it/s]\u001b[A\n",
            "Evaluating:  18%|█▊        | 357/1942 [00:30<02:15, 11.68it/s]\u001b[A\n",
            "Evaluating:  25%|██▍       | 476/1942 [00:40<02:04, 11.74it/s]\u001b[A\n",
            "Evaluating:  31%|███       | 596/1942 [00:50<01:54, 11.79it/s]\u001b[A\n",
            "Evaluating:  37%|███▋      | 716/1942 [01:00<01:43, 11.83it/s]\u001b[A\n",
            "Evaluating:  43%|████▎     | 836/1942 [01:10<01:33, 11.86it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lebLzSix0J6"
      },
      "source": [
        "# Test your model on a sample (Inference)\n",
        "from farm.infer import Inferencer\n",
        "from pprint import PrettyPrinter\n",
        "\n",
        "infer_model = Inferencer(\n",
        "    processor=processor, \n",
        "    model=model, \n",
        "    task_type=\"text_classification\", \n",
        "    gpu=True\n",
        ")\n",
        "\n",
        "basic_texts = [\n",
        "    {\"text\": \"기생충,,, 이 영화 정말 재밌네요.\"},\n",
        "    {\"text\": \"황정민 나오는 영화는 다 볼만한듯?\"},\n",
        "]\n",
        "result = infer_model.inference_from_dicts(dicts=basic_texts)\n",
        "PrettyPrinter().pprint(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}